name: Daily Price Scraping

on:
  workflow_dispatch:
    inputs:
      verbose:
        description: 'Enable verbose logging'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
  schedule:
    - cron: '0 8 * * *'  # 8 AM UTC daily (11:30 AM Tehran time)

permissions:
  contents: write
  issues: write

env:
  VERBOSE: ${{ github.event.inputs.verbose || 'true' }}
  OUTPUT: 'true'
  NODE_VERSION: '20'
  DIGIKALA_COOKIES: ${{ secrets.DIGIKALA_COOKIES }}

jobs:
  scrape-and-commit:
    name: Scrape Prices and Commit Results
    runs-on: ubuntu-latest
    timeout-minutes: 45
    
    outputs:
      stats: ${{ steps.scrape.outputs.stats }}
      success: ${{ steps.scrape.outputs.success }}
      commit-sha: ${{ steps.commit.outputs.sha }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Setup Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: 'scripts/package.json'
      
      - name: Cache node_modules
        uses: actions/cache@v4
        id: npm-cache
        with:
          path: scripts/node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('scripts/package.json') }}
          restore-keys: |
            ${{ runner.os }}-node-
      
      - name: Install dependencies
        working-directory: scripts
        run: |
          if [ "${{ steps.npm-cache.outputs.cache-hit }}" != 'true' ]; then
            npm install --no-audit
          fi
        timeout-minutes: 5
      
      - name: Run price scraper
        id: scrape
        working-directory: scripts
        run: |
          node webScraping.js
          
          # Read stats and set outputs
          if [ -f stats.json ]; then
            {
              echo "stats<<EOF"
              cat stats.json
              echo "EOF"
            } >> "$GITHUB_OUTPUT"
            
            STATS=$(cat stats.json)
            # Extract individual values for commit message
            PROCESSED=$(echo "$STATS" | jq -r '.processed')
            FAILED=$(echo "$STATS" | jq -r '.failed')
            SKIPPED=$(echo "$STATS" | jq -r '.skipped')
            TOTAL=$(echo "$STATS" | jq -r '.total')
            
            echo "processed=$PROCESSED" >> $GITHUB_OUTPUT
            echo "failed=$FAILED" >> $GITHUB_OUTPUT
            echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
            echo "total=$TOTAL" >> $GITHUB_OUTPUT
            
            # Success if we processed at least 50% or if all were skipped (already done)
            if [ "$FAILED" -eq 0 ] || [ "$PROCESSED" -gt 0 ]; then
              echo "success=true" >> $GITHUB_OUTPUT
            else
              echo "success=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "success=false" >> $GITHUB_OUTPUT
          fi
        timeout-minutes: 30
        continue-on-error: true
      
      - name: Convert Excel to JSON
        if: steps.scrape.outputs.success == 'true'
        working-directory: scripts
        run: node xl-json.js
        timeout-minutes: 10
        continue-on-error: true
      
      - name: Prepare commit message
        id: commit-msg
        if: steps.scrape.outputs.success == 'true'
        run: |
          DATE=$(date +'%Y-%m-%d')
          PROCESSED="${{ steps.scrape.outputs.processed }}"
          FAILED="${{ steps.scrape.outputs.failed }}"
          SKIPPED="${{ steps.scrape.outputs.skipped }}"
          TOTAL="${{ steps.scrape.outputs.total }}"
          
          # Calculate success rate
          if [ "$TOTAL" -gt 0 ]; then
            SUCCESS_RATE=$(( PROCESSED * 100 / TOTAL ))
          else
            SUCCESS_RATE=0
          fi
          
          # Create commit message file
          echo "ðŸ“Š Price update for $DATE" > commit-msg.txt
          echo "" >> commit-msg.txt
          echo "âœ… Products with price data: $PROCESSED" >> commit-msg.txt
          echo "âš ï¸ Out of stock / Failed: $FAILED" >> commit-msg.txt
          echo "â­ï¸ Skipped (already updated): $SKIPPED" >> commit-msg.txt
          echo "ðŸ“Š Total tracked: $TOTAL" >> commit-msg.txt
          echo "ðŸ“ˆ Success rate: $SUCCESS_RATE%" >> commit-msg.txt
          echo "" >> commit-msg.txt
          echo "Scraped at: $(date -u +'%Y-%m-%d %H:%M:%S UTC')" >> commit-msg.txt
          
          # Export values for next step
          echo "date=$DATE" >> $GITHUB_OUTPUT
          echo "processed=$PROCESSED" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT
          echo "skipped=$SKIPPED" >> $GITHUB_OUTPUT
          echo "total=$TOTAL" >> $GITHUB_OUTPUT
          echo "rate=$SUCCESS_RATE" >> $GITHUB_OUTPUT
      
      - name: Commit and push changes
        id: commit
        if: steps.scrape.outputs.success == 'true'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          
          # Stage all changes
          git add -A
          
          # Check if there are changes to commit
          if git diff --cached --quiet; then
            echo "No changes to commit"
            echo "sha=none" >> $GITHUB_OUTPUT
            rm -f commit-msg.txt
            exit 0
          fi
          
          # Commit with message from file
          git commit -F commit-msg.txt
          rm -f commit-msg.txt
          
          # Push changes
          git push
          
          # Get commit SHA
          SHA=$(git rev-parse HEAD)
          echo "sha=$SHA" >> $GITHUB_OUTPUT
          echo "Committed: $SHA"
      
      - name: Upload stats artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraping-stats-${{ github.run_id }}
          path: scripts/stats.json
          retention-days: 30
          if-no-files-found: warn
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: debug-logs-${{ github.run_id }}
          path: |
            scripts/*.log
            scripts/output.json
          retention-days: 7
          if-no-files-found: ignore

  # Job to notify on failure
  notify-on-failure:
    name: Send Failure Notification
    needs: scrape-and-commit
    if: failure() || needs.scrape-and-commit.outputs.success == 'false'
    runs-on: ubuntu-latest
    steps:
      - name: Prepare failure notification
        id: notify
        run: |
          DATE=$(date +'%Y-%m-%d')
          RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          
          echo "subject=âŒ Price scraping failed for $DATE" >> $GITHUB_OUTPUT
          echo "date=$DATE" >> $GITHUB_OUTPUT
          echo "url=$RUN_URL" >> $GITHUB_OUTPUT
      
      # Create GitHub Issue for tracking
      - name: Create GitHub Issue
        if: github.event_name == 'schedule'  # Only for scheduled runs, not manual
        uses: actions/github-script@v7
        with:
          script: |
            const title = `âŒ Scraping failed on ${new Date().toISOString().split('T')[0]}`;
            const body = `The daily price scraping job failed.
            
            **Run Details:**
            - Workflow: ${{ github.workflow }}
            - Run ID: ${{ github.run_id }}
            - Run URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            
            **Next Steps:**
            1. Check the logs for error details
            2. Verify API endpoints are accessible
            3. Check if Digikala API structure changed
            
            cc: @${{ github.repository_owner }}`;
            
            github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['bug', 'automation-failure']
            });
        continue-on-error: true

  # Optional: Update dashboard metadata
  update-dashboard:
    name: Update Dashboard Metadata
    needs: scrape-and-commit
    if: needs.scrape-and-commit.outputs.success == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Update last-run metadata
        run: |
          DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
          echo "{\"lastRun\": \"$DATE\", \"status\": \"success\", \"commit\": \"${{ needs.scrape-and-commit.outputs.commit-sha }}\"}" > last-run.json
          
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add last-run.json
          git diff --cached --quiet || (git commit -m "ðŸ¤– Update last-run metadata [skip ci]" && git push)
